<!DOCTYPE html><html lang="zh-cn"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="首先是下面的流程图,最终呈现的效果为,用户开启语音输入,识别问题后调用GPT获得结果的同时向讯飞发起语音合成."><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>ChatGPT与讯飞语音识别和语音合成结合中的问题总结 | Mccc</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 7.3.0"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Archives</a></nav><div class="container post-meta"><div class="post-time">2023-09-21</div></div></div><div class="container post-header"><h1>ChatGPT与讯飞语音识别和语音合成结合中的问题总结</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion"></summary><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB"><span class="toc-number">1.</span> <span class="toc-text">1.语音识别</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E8%AF%AD%E9%9F%B3%E9%87%87%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 语音采集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">1.3 本地数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3-1-%E5%8E%9F%E7%94%9F%E6%96%B9%E6%B3%95%E5%BC%80%E5%8F%91"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.3.1 原生方法开发</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3-2-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93"><span class="toc-number">1.2.2.</span> <span class="toc-text">1.3.2 第三方库</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-%E6%95%B0%E6%8D%AE%E6%8F%90%E4%BA%A4"><span class="toc-number">1.3.</span> <span class="toc-text">1.4 数据提交</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-%E7%BB%93%E6%9E%9C"><span class="toc-number">1.4.</span> <span class="toc-text">1.5 结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-6%E5%85%B6%E4%BB%96"><span class="toc-number">1.5.</span> <span class="toc-text">1.6其他</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90"><span class="toc-number">2.</span> <span class="toc-text">2.语音合成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-GPT%E5%9B%9E%E7%AD%94%E5%88%86%E6%AE%B5"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 GPT回答分段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E5%A4%84%E7%90%86%E8%AF%AD%E9%9F%B3%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 处理语音数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E6%92%AD%E6%94%BE%E9%9F%B3%E9%A2%91%E6%95%B0%E6%8D%AE"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 播放音频数据</span></a></li></ol></li></ol></details></div><div class="container post-content"><p>首先是下面的流程图,最终呈现的效果为,用户开启语音输入,识别问题后调用GPT获得结果的同时向讯飞发起语音合成.</p>
<img src="/images/chatgpt/2.png">
___

<h3 id="1-语音识别"><a href="#1-语音识别" class="headerlink" title="1.语音识别"></a>1.语音识别</h3><h4 id="1-1-语音采集"><a href="#1-1-语音采集" class="headerlink" title="1.1 语音采集"></a>1.1 语音采集</h4><p>语音识别目前由于浏览器的差异,目前有三种方式可用于进行语音采集</p>
<ol>
<li><code>MediaRecorder</code>:可以捕获浏览器中播放的音频或视频，并将其保存为文件或流媒体</li>
<li><code>AudioWorklet</code>:可以在独立的工作线程中编写和执行音频处理算法，而不会阻塞主线程的运行,同样这是一项实验功能,所以在一些老旧的浏览器并不支持.</li>
<li><code>ScriptProcessor</code>:古董级的处理,目前来说所有的浏览器都支持,实际中发现华为的一系列手机支持情况不是很好</li>
</ol>
<p>这里建议三种方式同时使用,这里有两个库可以参考:</p>
<ol>
<li><p>如果是简单的功能不需要做兼容处理可以考虑这个库.核心代码很简单,可以根据自己的需求重写<a target="_blank" rel="noopener" href="https://github.com/2fps/recorder">连接</a></p>
</li>
<li><p>对于复杂项目建议使用第三方库 <a target="_blank" rel="noopener" href="https://github.com/xiangyuecn/Recorder">链接</a></p>
</li>
</ol>
<br>
#### 1.2 静默处理 
本地语音采集开启后,再连接讯飞socket前,可以在本地添加静默时间,即用户在一定时间内没有声音输出时,即可终止所有操作

<p>下面是rxjs的实现方式,可以参考</p>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">readonly startRecorder$ = new Subject&lt;void&gt;(); //开始连接语音</span><br><span class="line">readonly powerLevel$ = new Subject&lt;number&gt;(); //音量等级,此处是粗略的计算</span><br><span class="line"> </span><br><span class="line">this.vadEosSubscription = this.powerLevel$</span><br><span class="line">     .pipe(</span><br><span class="line">       first((val) =&gt; val &gt; 5),//截取音量大于5的值后完成源Observable</span><br><span class="line">       timeout(5000),//5S后查看当前最大音量等级值,若5s内没有符合条件的值则源Observable失败</span><br><span class="line">       repeatWhen(() =&gt; this.startRecorder$),每次连接语音时重启源Observable</span><br><span class="line">       catchError((e) =&gt; &#123;</span><br><span class="line">       //timeout失败错误处理,表示用户5秒内没有符合要求的音量值</span><br><span class="line">         return throwError(() =&gt; new Error(e));</span><br><span class="line">       &#125;)</span><br><span class="line">     )</span><br><span class="line">     .subscribe((r) =&gt; &#123;</span><br><span class="line">  	    //有符合要求的音量值可以连接讯飞socket</span><br><span class="line">     &#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>关于粗略的计算音频PCM信号的音量,可以采用采样点幅值的面积(能量)来计算,计算公式为:<code>20*log10(x/y)</code>;此处不过多考虑,可以具体搜索PCM计算音量</p>
<br>


<h4 id="1-3-本地数据处理"><a href="#1-3-本地数据处理" class="headerlink" title="1.3 本地数据处理"></a>1.3 本地数据处理</h4><p>讯飞语音识别需要满足的数据格式如下:</p>
<ol>
<li>未压缩的PCM格式，每次发送音频间隔40ms，每次发送音频字节数1280B；</li>
<li>讯飞定制speex格式，每次发送音频间隔40ms，假如16k的压缩等级为7，则每次发送61B的整数倍；</li>
<li>标准开源speex格式，每次发送音频间隔40ms，假如16k的压缩等级为7，则每次发送60B的整数倍；</li>
</ol>
<br>

<h5 id="1-3-1-原生方法开发"><a href="#1-3-1-原生方法开发" class="headerlink" title="1.3.1 原生方法开发"></a>1.3.1 原生方法开发</h5><p>如果使用JS的原生方法开发,获取的数据为Float32格式,由于数据过于密集,这里就需要使用worker来对原始采集的数据进行转换,具体到不同的框架都有自己的worker实现,不过多说明.</p>
<p>具体的转换可以参考<code>worker.ts</code>代码,这里是将数据最后转成了PCM(16位小端LE)</p>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">//这里定义三个类型主要确定数据的开始和结束,讯飞的demo里也是类似的实现</span><br><span class="line">export interface Worker &#123;</span><br><span class="line">  type: &#x27;init&#x27; | &#x27;message&#x27; | &#x27;stop&#x27;;</span><br><span class="line">  data: &#123;</span><br><span class="line">    frameSize: number;</span><br><span class="line">    sampleRate: number;</span><br><span class="line">    audioBuffers: Float32Array;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">addEventListener(&#x27;message&#x27;, (event: MessageEvent&lt;Worker&gt;) =&gt; &#123;</span><br><span class="line">  const &#123; data &#125; = event;</span><br><span class="line">  const &#123; type &#125; = data;</span><br><span class="line">  switch (type) &#123;</span><br><span class="line">    case &#x27;init&#x27;:</span><br><span class="line">      transAudioData.init(data.data.frameSize, data.data.sampleRate);</span><br><span class="line">      break;</span><br><span class="line">    case &#x27;message&#x27;:</span><br><span class="line">      transAudioData.frameBuffer.push(</span><br><span class="line">        ...transAudioData.transcode(data.data.audioBuffers)</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      //截取参数设置的帧数大小</span><br><span class="line">      if (</span><br><span class="line">        transAudioData.frameBuffer &amp;&amp;</span><br><span class="line">        transAudioData.frameBuffer.length &gt;= transAudioData.frameSize</span><br><span class="line">      ) &#123;</span><br><span class="line">        postMessage(&#123;</span><br><span class="line">          frameBuffer: transAudioData.frameBuffer.splice(</span><br><span class="line">            0,</span><br><span class="line">            transAudioData.frameSize</span><br><span class="line">          ),</span><br><span class="line">          isLastFrame: false,</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">      break;</span><br><span class="line">    case &#x27;stop&#x27;:</span><br><span class="line">      postMessage(&#123;</span><br><span class="line">        frameBuffer: transAudioData.frameBuffer.splice(</span><br><span class="line">          0,</span><br><span class="line">          transAudioData.frameSize</span><br><span class="line">        ),</span><br><span class="line">        isLastFrame: true,</span><br><span class="line">      &#125;);</span><br><span class="line">      transAudioData.frameBuffer = [];</span><br><span class="line">      break;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">const transAudioData: &#123;</span><br><span class="line">  inputSampleRate: number;</span><br><span class="line">  inputSampleBits: number;</span><br><span class="line">  frameSize: number;</span><br><span class="line">  frameBuffer: Array&lt;Float32Array&gt;;</span><br><span class="line">  init: (frameSize: number, sampleRate: number) =&gt; void;</span><br><span class="line">  transcode: (e: Float32Array) =&gt; Float32Array[];</span><br><span class="line">  to16kHz: (e: Float32Array) =&gt; Float32Array;</span><br><span class="line">  to16BitPCM: (e: Float32Array) =&gt; DataView;</span><br><span class="line">&#125; = &#123;</span><br><span class="line">  inputSampleRate: 0, //采样率</span><br><span class="line">  inputSampleBits: 16, //采样位数</span><br><span class="line">  frameSize: 1280,</span><br><span class="line">  frameBuffer: [],</span><br><span class="line"></span><br><span class="line">  init(frameSize, sampleRate) &#123;</span><br><span class="line">    this.inputSampleRate = sampleRate;</span><br><span class="line">    this.frameSize = frameSize;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  transcode(audioData) &#123;</span><br><span class="line">    let output: any = transAudioData.to16kHz(audioData);</span><br><span class="line">    output = transAudioData.to16BitPCM(output);</span><br><span class="line">    output = Array.from(new Uint8Array(output.buffer));</span><br><span class="line">    return output;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  to16kHz(audioData) &#123;</span><br><span class="line">    const data = new Float32Array(audioData);</span><br><span class="line">    const fitCount = Math.round(data.length * (this.inputSampleRate / 44100));</span><br><span class="line">    const newData = new Float32Array(fitCount);</span><br><span class="line">    const springFactor = (data.length - 1) / (fitCount - 1);</span><br><span class="line">    newData[0] = data[0];</span><br><span class="line">    for (let i = 1; i &lt; fitCount - 1; i++) &#123;</span><br><span class="line">      const tmp = i * springFactor;</span><br><span class="line">      const before = Number(Math.floor(tmp).toFixed());</span><br><span class="line">      const after = Number(Math.ceil(tmp).toFixed());</span><br><span class="line">      const atPoint = tmp - before;</span><br><span class="line">      newData[i] = data[before] + (data[after] - data[before]) * atPoint;</span><br><span class="line">    &#125;</span><br><span class="line">    newData[fitCount - 1] = data[data.length - 1];</span><br><span class="line">    return newData;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  to16BitPCM(input) &#123;</span><br><span class="line">    const dataLength = input.length * (16 / 8);</span><br><span class="line">    const dataBuffer = new ArrayBuffer(dataLength);</span><br><span class="line">    const dataView = new DataView(dataBuffer);</span><br><span class="line">    let offset = 0;</span><br><span class="line">    for (let i = 0; i &lt; input.length; i++, offset += 2) &#123;</span><br><span class="line">      const s = Math.max(-1, Math.min(1, input[i]));</span><br><span class="line">      dataView.setInt16(offset, s &lt; 0 ? s * 0x8000 : s * 0x7fff, true);</span><br><span class="line">    &#125;</span><br><span class="line">    return dataView;</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h5 id="1-3-2-第三方库"><a href="#1-3-2-第三方库" class="headerlink" title="1.3.2 第三方库"></a>1.3.2 第三方库</h5><p>一般第三方库有自己的数据处理逻辑,可以直接拿到符合要求的数据格式</p>
<br>

<h4 id="1-4-数据提交"><a href="#1-4-数据提交" class="headerlink" title="1.4 数据提交"></a>1.4 数据提交</h4><p>通过上述介绍,在实际的开发中音频采集的状态和音频数据会是两条完全异步的数据流,具体的实现有很多方法,这里我个人采用了Rxjs,定义两条数据流,同时定义数据类型</p>
<ol>
<li>音频采集的开启和关闭(RecorderManagerObservable)</li>
</ol>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 语音录制状态</span><br><span class="line"> */</span><br><span class="line">export interface RecorderManagerObservable &#123;</span><br><span class="line">  status: RecorderManagerStatus;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export enum RecorderManagerStatus &#123;</span><br><span class="line">  /**</span><br><span class="line">   * 未连接</span><br><span class="line">   */</span><br><span class="line">  &#x27;unconnected&#x27; = &#x27;unconnected&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 状态:连接</span><br><span class="line">   * 本地语音有初始静默处理,此时表示已经有有效数据.可以连接讯飞语音识别socket</span><br><span class="line">   */</span><br><span class="line">  &#x27;open&#x27; = &#x27;open&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 语音断开</span><br><span class="line">   */</span><br><span class="line">  &#x27;close&#x27; = &#x27;close&#x27;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>音频数据的本地缓存(AudioDataByRecorderObservable)</li>
</ol>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 语音数据(本地Recorder获取)</span><br><span class="line"> * IAT(音频转文字)使用</span><br><span class="line"> */</span><br><span class="line">export interface AudioDataByRecorderObservable&lt;T extends RecorderMangerData&gt; &#123;</span><br><span class="line">  status: AudioDataByRecorderStatus;</span><br><span class="line">  data: T;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export enum AudioDataByRecorderStatus &#123;</span><br><span class="line">  /**</span><br><span class="line">   * 数据帧记录</span><br><span class="line">   */</span><br><span class="line">  &#x27;frameRecorded&#x27; = &#x27;frameRecorded&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 结束</span><br><span class="line">   */</span><br><span class="line">  &#x27;end&#x27; = &#x27;end&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 错误</span><br><span class="line">   */</span><br><span class="line">  &#x27;error&#x27; = &#x27;error&#x27;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//数据类型</span><br><span class="line">export type RecorderMangerData =</span><br><span class="line">  | RecorderMangerFrameRecordedData</span><br><span class="line">  | RecorderMangerStopData</span><br><span class="line">  | RecorderMangerErrorData;</span><br><span class="line"></span><br><span class="line">//录制中</span><br><span class="line">export type RecorderMangerFrameRecordedData = &#123;</span><br><span class="line">  audioData: string;</span><br><span class="line">  isLastFrame: boolean;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">//录制结束</span><br><span class="line">export type RecorderMangerStopData = null;</span><br><span class="line"></span><br><span class="line">//录制失败</span><br><span class="line">export type RecorderMangerErrorData = string;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>具体的流程如前面的图里所示:<br><code>开启录音(处理并缓存音频数据</code>)&#x3D;&gt;<code>静默处理</code>&#x3D;&gt;<code>终止/连接socket</code>&#x3D;&gt;<code>根据实际情况持续提交音频数据</code>&#x3D;&gt;<code>结束录音</code>&#x3D;&gt;<code>获得结果</code></p>
<h4 id="1-5-结果"><a href="#1-5-结果" class="headerlink" title="1.5 结果"></a>1.5 结果</h4><p>之后从讯飞socket中获取结果后即可向GPT发起问题,等待GPT的回答</p>
<h4 id="1-6其他"><a href="#1-6其他" class="headerlink" title="1.6其他"></a>1.6其他</h4><p>关于开启和关闭录音,这里一般有两种交互模式,即用户点击开启&#x2F;点击关闭和长按输入&#x2F;松开结束,这里需要根据自己的实际环境决定采用哪种方式,由于在获取音频的时候,第一次浏览器会有弹框询问,所以可以考虑将获取音频和开启录制分开来实现,但是在某些H5环境下每次都会询问用户是否授权录音,所以这里需要着重考虑清楚</p>
<hr>
<h3 id="2-语音合成"><a href="#2-语音合成" class="headerlink" title="2.语音合成"></a>2.语音合成</h3><img src="/images/chatgpt/3.png">
由于讯飞的语音合成API为流式输出,但是只支持单次上传,而实际的需求是GPT回答的同时语音输出,所以在调用讯飞语音合成时,首先需要根据回答内容对其进行分段,然后顺序调用讯飞API拿取音频结果并播放,基于以上的流程图我们可以将整个过程分为三个部分的功能

<ol>
<li>GPT数据的分段功能</li>
<li>请求和获取语音数据</li>
<li>播放语音数据</li>
</ol>
<h4 id="2-1-GPT回答分段"><a href="#2-1-GPT回答分段" class="headerlink" title="2.1 GPT回答分段"></a>2.1 GPT回答分段</h4><p>由于GPT的回答是流式输出,需要临时缓存每一次的回复数据,并分段.而分段时我们需要同时考虑以下几个条件:</p>
<ol>
<li>当前内容是否处于分段节点(回车,逗号,句号,长度是否满足)</li>
<li>请求锁是否打开(是否有正在进行中的websocket(讯飞API))</li>
<li>播放音频的指针是否合适(本地没有积压过多的待播放音频数据)</li>
</ol>
<p>第一个条件:为了满足每一段的语音节点都处于断句出,这样可以让语音的输出更有可读性.</p>
<p>第二个条件:因为语音的输出具有连贯性,只有前一段的语音数据全部接收完毕,下一段的语音数据才具有意义.所以需要保证前一段的语音数据接收完毕后才可以发起新的请求</p>
<p>第三个条件:由于API的整个过程在时间上是快于语音的播放,并且为了尽可能少的请求API(减少调用次数),所以本地的尽可能少的缓存语音数据,这里可以缓存一段待播放的音频数据即可,后续可以根据自己的需要调整阈值</p>
<p>注意:在这个过程中我们同时需要记录以下几个数据</p>
<ol>
<li>GPT回答分段指针:处理语音数据时,需要根据指针持续更新对应片段的语音数据</li>
<li>结束位:GPT回答分段是否已经结束,用于通知播放器是否可以停止播放音频数据</li>
</ol>
<h4 id="2-2-处理语音数据"><a href="#2-2-处理语音数据" class="headerlink" title="2.2 处理语音数据"></a>2.2 处理语音数据</h4><p>在是否可以调用API时,我们需要满足以下几个条件</p>
<ol>
<li>是否有分段内容</li>
<li>请求锁是否打开(保证每次只调用一个API)</li>
<li>待播放音频数据是否超过阈值(本地没有积压过多的待播放音频数据)</li>
</ol>
<p>当上述三个条件都满足时,即可开始调用API;</p>
<p>同时针对单次的讯飞API请求,我们在获得数据的时候需要根据GPT回答内容的分段标记指针位置,在这个过程中更新对应指针的语音数据,需要额外注意的是,由于拿到的语音数据不能直接播放,需要经过worker计算才可,具体的代码由于原生和各个框架的处理情况不一样,可以根据自己的实际开发环境实现.</p>
<h4 id="2-3-播放音频数据"><a href="#2-3-播放音频数据" class="headerlink" title="2.3 播放音频数据"></a>2.3 播放音频数据</h4><p>从worker拿到音频数据并缓存后,根据回答分段时记录的结束位判断是否可以继续播放,开始播放时即可更新播放的指针位置和音频数据长度,同时通知GPT回答分段本地的待播放音频数据是否超过阈值.</p>
<hr>
<p>以上即是语音合成的整个过程,这个过程代码过于分散,可以根据自己的实际开发环境按照上述的过程处理即可,额外需要注意的时,由于整个过程中存在大量的异步处理,这里个人采用rxjs的方式处理,对应的需要创建以下几个Ob,可以参考</p>
<ul>
<li>GPTSectionOb(GPT分段Observable)</li>
</ul>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * GPT回答内容分段</span><br><span class="line"> */</span><br><span class="line">export interface GPTSectionObservable &#123;</span><br><span class="line">  status: GPTSectionStatus;</span><br><span class="line">  data?: AsAny.AsAny;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * GPT回答状态</span><br><span class="line"> */</span><br><span class="line">export enum GPTSectionStatus &#123;</span><br><span class="line">  &#x27;start&#x27; = &#x27;start&#x27;, //初始化</span><br><span class="line">  &#x27;doing&#x27; = &#x27;doing&#x27;, //GPT回答中</span><br><span class="line">  &#x27;end&#x27; = &#x27;end&#x27;, //回答结束</span><br><span class="line">  &#x27;cancel&#x27; = &#x27;cancel&#x27;, //取消</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>TTS_PlayerStatusObservable(控制播放器Observable,可以不需要,这里因为项目内还需要处理VRM和其他的操作)</li>
</ul>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">export interface TTS_PlayerStatusObservable &#123;</span><br><span class="line">  status: TTS_Status;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//音频转文字播放器状态</span><br><span class="line">export enum TTS_Status &#123;</span><br><span class="line">  /**</span><br><span class="line">   * 初始化</span><br><span class="line">   */</span><br><span class="line">  &#x27;ready&#x27; = &#x27;ready&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 开始播放</span><br><span class="line">   */</span><br><span class="line">  &#x27;start&#x27; = &#x27;start&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 播放中</span><br><span class="line">   */</span><br><span class="line">  &#x27;playing&#x27; = &#x27;playing&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 播放结束</span><br><span class="line">   */</span><br><span class="line">  &#x27;end&#x27; = &#x27;end&#x27;,</span><br><span class="line">  /**</span><br><span class="line">   * 取消播放</span><br><span class="line">   */</span><br><span class="line">  &#x27;cancel&#x27; = &#x27;cancel&#x27;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>AudioDataPlayingQueueOb(记录播放指针和音频数据长度的Observable)</li>
</ul>
<div class="noise-code-block" style="--code-block-max-height:inherit;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export interface AudioDataPlayingQueueObservable &#123;</span><br><span class="line">  data: Array&lt;AsAny.AsAny&gt;;//音频数据</span><br><span class="line">  index: number; //当前播放的指针</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></div></div><div class="post-main post-comment"></div></article><link rel="stylesheet" type="text/css" href="/css/third-party/font-awesome/4.5.0/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.css"><script src="/js/third-party/jquery/2.0.3/jquery.min.js"></script><script src="/js/third-party/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>